# -*- coding: utf-8 -*-
"""contadorDePessoas.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nQuOZlKfSUrNu31sP-wJ6GClhe1v__0u
"""

from IPython.display import display, Javascript
from google.colab.output import eval_js
from base64 import b64decode

def take_photo(filename='photo.jpg', quality=0.8):
  js = Javascript('''
    async function takePhoto(quality) {
      const div = document.createElement('div');
      const capture = document.createElement('button');
      capture.textContent = 'Capture';
      div.appendChild(capture);

      const video = document.createElement('video');
      video.style.display = 'block';
      const stream = await navigator.mediaDevices.getUserMedia({video: true});

      document.body.appendChild(div);
      div.appendChild(video);
      video.srcObject = stream;
      await video.play();

      // Resize the output to fit the video element.
      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);

      // Wait for Capture to be clicked.
      // await new Promise((resolve) => capture.onclick = resolve);

      const canvas = document.createElement('canvas');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      canvas.getContext('2d').drawImage(video, 0, 0);
      stream.getVideoTracks()[0].stop();
      div.remove();
      return canvas.toDataURL('image/jpeg', quality);
    }
    ''')
  display(js)
  data = eval_js('takePhoto({})'.format(quality))
  binary = b64decode(data.split(',')[1])
  with open(filename, 'wb') as f:
    f.write(binary)
  return filename

from IPython.display import Image
try:
  filename = take_photo()
  print('Saved to {}'.format(filename))
  
  # Show the image which was just taken.
  display(Image(filename))
except Exception as err:
  # Errors will be thrown if the user does not have a webcam or if they do not
  # grant the page permission to access it.
  print(str(err))

imagem = take_photo('s24_00.jpg')

print(imagem)

path_base = '/content/drive/My Drive/DataSetImagens/'
treino = 'treino/'
teste = 'teste/'
limiar = 7
meuCodigo = '05'
for i in range(10):
  if i < limiar:
    imagem = take_photo(path_base+treino+'s%s_%02i.jpg' % (meuCodigo, i))
  else:  
    imagem = take_photo(path_base+teste+'s%s_%02i.jpg' % (meuCodigo, i))
  print(imagem)

#Nome das imagens para rodar
nome_imagens_treino = []
nome_imagens_teste = []
#Labels das imagens
labels_imagens_treino = []
labels_imagens_teste = []

from os import walk
#Imagens de treino
for (dirpath, dirnames, filenames) in walk(path_base+treino):
  for arquivo in filenames:
    if '.jpg' in arquivo or '.jpeg' in arquivo :
      nome_imagens_treino.append(arquivo)
      labels_imagens_treino.append(arquivo[1:3])

print(len(nome_imagens_treino))

#Imagens de teste
for (dirpath, dirnames, filenames) in walk(path_base+teste):
  for arquivo in filenames:
    if '.jpg' in arquivo or '.jpeg' in arquivo :
      nome_imagens_teste.append(arquivo)
      labels_imagens_teste.append(arquivo[1:3])

print(len(nome_imagens_teste))

# Commented out IPython magic to ensure Python compatibility.
import cv2
import matplotlib.pyplot as plt
# %matplotlib inline

classificador = cv2.CascadeClassifier('/content/drive/My Drive/haarcascade_frontalface_default.xml')

print(path_base+treino+nome_imagens_treino[30])
img = cv2.imread(path_base+treino+nome_imagens_treino[30], cv2.IMREAD_GRAYSCALE)
faces_detectadas = classificador.detectMultiScale(img, 1.3, 5)
img_roi = None
for x,y,w,h in faces_detectadas:
  img_roi = img[y:y+h, x:x+w]
#Para verificar se uma imagem foi detectada
if img_roi is not None:
  print(img_roi.shape)
  plt.imshow(img_roi, cmap='gray')
  plt.show()

#Labels das imagens
labels_imagens_treino = []
labels_imagens_teste = []

#Imagens tratadas
imagens_roi_treino = []
imagens_roi_teste = []

for nome_imagem in nome_imagens_treino:
  print(path_base+treino+nome_imagem)
  img = cv2.imread(path_base+treino+nome_imagem, cv2.IMREAD_GRAYSCALE)
  faces_detectadas = classificador.detectMultiScale(img, 1.3, 5)
  img_roi = None
  for x,y,w,h in faces_detectadas:
    img_roi = img[y:y+h, x:x+w]
  #Para verificar se uma imagem foi detectada
  if img_roi is not None:
    img_roi = cv2.resize(img_roi, (200,200))
    imagens_roi_treino.append(img_roi)
    labels_imagens_treino.append(nome_imagem[1:3])
print(len(imagens_roi_treino))

for nome_imagem in nome_imagens_teste:
  # print(path_base+treino+nome_imagem)
  img = cv2.imread(path_base+teste+nome_imagem, cv2.IMREAD_GRAYSCALE)
  faces_detectadas = classificador.detectMultiScale(img, 1.3, 5)
  img_roi = None
  for x,y,w,h in faces_detectadas:
    img_roi = img[y:y+h, x:x+w]
  #Para verificar se uma imagem foi detectada
  if img_roi is not None:
    img_roi = cv2.resize(img_roi, (200,200))
    imagens_roi_teste.append(img_roi)
    labels_imagens_teste.append(nome_imagem[1:3])
print(len(imagens_roi_teste))

#Converter os Labels para np.int32
import numpy as np
labels_imagens_teste = np.asarray(labels_imagens_teste, dtype = np.int32)
labels_imagens_treino = np.asarray(labels_imagens_treino, dtype = np.int32)

#Para verificar a acur치cia do modelo gerado
from sklearn.metrics import accuracy_score

#Carrega o modelo de Eingen Faces
modelo_eingen = cv2.face.EigenFaceRecognizer_create()
#Treinar o modelo de Eingen
modelo_eingen.train(imagens_roi_treino,labels_imagens_treino)
#Verifica o modelo
resultado = modelo_eingen.predict(imagens_roi_teste[5])
print(resultado)
print(labels_imagens_teste[5])
#Verifica a acur치cia do modelo de Eingen
predicoes_eingen = []
for imagem in imagens_roi_teste:
  predicoes_eingen.append(modelo_eingen.predict(imagem)[0])

resultado_modelo_eingen = accuracy_score(labels_imagens_teste, predicoes_eingen)
print(resultado_modelo_eingen)

#Carrega o modelo de FisherFaces
modelo_fisher = cv2.face.FisherFaceRecognizer_create()
#Treinar o modelo de Fisher
modelo_fisher.train(imagens_roi_treino,labels_imagens_treino)
#Verifica o modelo
resultado = modelo_fisher.predict(imagens_roi_teste[5])
print(resultado)
print(labels_imagens_teste[5])
#Verifica a acur치cia do modelo de fisher
predicoes_fisher = []
for imagem in imagens_roi_teste:
  predicoes_fisher.append(modelo_fisher.predict(imagem)[0])

resultado_modelo_fisher = accuracy_score(labels_imagens_teste, predicoes_fisher)
print(resultado_modelo_fisher)

#Carrega o modelo de LBPH
modelo_LBPH = cv2.face.LBPHFaceRecognizer_create()
#Treinar o modelo de LBPH
modelo_LBPH.train(imagens_roi_treino,labels_imagens_treino)
#Verifica o modelo
resultado = modelo_LBPH.predict(imagens_roi_teste[5])
print(resultado)
print(labels_imagens_teste[5])
#Verifica a acur치cia do modelo de LBPH
predicoes_LBPH = []
for imagem in imagens_roi_teste:
  predicoes_LBPH.append(modelo_LBPH.predict(imagem)[0])

resultado_modelo_LBPH = accuracy_score(labels_imagens_teste, predicoes_LBPH)
print(resultado_modelo_LBPH)

lucasimg = '/content/drive/My Drive/UNADJUSTEDNONRAW_thumb_1b09.jpg'

#Teste da verdade agora!
img = cv2.imread(lucasimg,cv2.IMREAD_GRAYSCALE)

faces_detectadas = classificador.detectMultiScale(img, 1.3, 5)
img_roi = None
for x,y,w,h in faces_detectadas:
  img_roi = img[y:y+h, x:x+w]
  #Para verificar se uma imagem foi detectada
if img_roi is not None:
  img_roi = cv2.resize(img_roi, (200,200))
  saidas = []
  saidas.append(modelo_eingen.predict(img_roi)) 
  saidas.append(modelo_fisher.predict(img_roi)) 
  saidas.append(modelo_LBPH.predict(img_roi))
  print(saidas)